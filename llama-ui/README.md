# Ultimate Llama AI Application

A full-stack AI application optimized for Apple Silicon with MLX integration.

## Features

- FastAPI Backend with SQLite database
- Next.js Frontend with TailwindCSS
- MLX optimizations for Apple Silicon
- Interactive Llama AI chat interface
- Command-line interface tools

## Getting Started

### Development Mode

```bash
# Start the backend
cd backend
source venv/bin/activate
python -m app.main

# In another terminal, start the frontend
cd frontend
npm run dev
```

Visit http://localhost:3000 to see the application.

## System Requirements

- macOS (Apple Silicon preferred)
- Python 3.11+
- Node.js 18+
- MLX for Apple Silicon optimization

## License

MIT
